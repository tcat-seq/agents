{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins with sk-proj-H4\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins with {openai_api_key[:10]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "openai_python_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [ {\"role\": \"user\", \"content\": \"What is 2+3\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 3 equals 5.\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "prompt = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If two trains start from the same point at the same time, one traveling north at 60 miles per hour and the other east at 80 miles per hour, how many minutes will it take until they are exactly 100 miles apart?\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [ {\"role\": \"user\", \"content\": question} ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's define the problem clearly:\n",
      "\n",
      "- Train A travels north at 60 mph.\n",
      "- Train B travels east at 80 mph.\n",
      "- Both start at the same point and at the same time.\n",
      "- We want to find the time \\( t \\) (in minutes) when the distance between the two trains is exactly 100 miles.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 1: Express positions after time \\( t \\) hours\n",
      "\n",
      "- Position of Train A after \\( t \\) hours: \\( (0, 60t) \\) (since it moves north).\n",
      "- Position of Train B after \\( t \\) hours: \\( (80t, 0) \\) (since it moves east).\n",
      "\n",
      "### Step 2: Distance between the trains after time \\( t \\)\n",
      "\n",
      "Using the distance formula:\n",
      "\\[\n",
      "d = \\sqrt{(80t - 0)^2 + (0 - 60t)^2} = \\sqrt{(80t)^2 + (60t)^2} = \\sqrt{6400t^2 + 3600t^2} = \\sqrt{10000t^2} = 100t.\n",
      "\\]\n",
      "\n",
      "### Step 3: Set distance to 100 miles and solve for \\( t \\)\n",
      "\n",
      "\\[\n",
      "100t = 100 \\implies t = 1 \\text{ hour}.\n",
      "\\]\n",
      "\n",
      "### Step 4: Convert to minutes\n",
      "\n",
      "\\[\n",
      "t = 1 \\text{ hour} = 60 \\text{ minutes}.\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "### **Answer:**\n",
      "\n",
      "It will take **60 minutes** for the two trains to be exactly 100 miles apart.\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages = messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's define the problem clearly:\n",
       "\n",
       "- Train A travels north at 60 mph.\n",
       "- Train B travels east at 80 mph.\n",
       "- Both start at the same point and at the same time.\n",
       "- We want to find the time \\( t \\) (in minutes) when the distance between the two trains is exactly 100 miles.\n",
       "\n",
       "---\n",
       "\n",
       "### Step 1: Express positions after time \\( t \\) hours\n",
       "\n",
       "- Position of Train A after \\( t \\) hours: \\( (0, 60t) \\) (since it moves north).\n",
       "- Position of Train B after \\( t \\) hours: \\( (80t, 0) \\) (since it moves east).\n",
       "\n",
       "### Step 2: Distance between the trains after time \\( t \\)\n",
       "\n",
       "Using the distance formula:\n",
       "\\[\n",
       "d = \\sqrt{(80t - 0)^2 + (0 - 60t)^2} = \\sqrt{(80t)^2 + (60t)^2} = \\sqrt{6400t^2 + 3600t^2} = \\sqrt{10000t^2} = 100t.\n",
       "\\]\n",
       "\n",
       "### Step 3: Set distance to 100 miles and solve for \\( t \\)\n",
       "\n",
       "\\[\n",
       "100t = 100 \\implies t = 1 \\text{ hour}.\n",
       "\\]\n",
       "\n",
       "### Step 4: Convert to minutes\n",
       "\n",
       "\\[\n",
       "t = 1 \\text{ hour} = 60 \\text{ minutes}.\n",
       "\\]\n",
       "\n",
       "---\n",
       "\n",
       "### **Answer:**\n",
       "\n",
       "It will take **60 minutes** for the two trains to be exactly 100 miles apart."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One business area ripe for an Agentic AI opportunity is **Supply Chain and Logistics Management**.\n",
      "\n",
      "### Why Supply Chain and Logistics?\n",
      "- **Complexity and Dynamism**: Supply chains involve multiple stakeholders, fluctuating demand, changing regulations, and unpredictable disruptions (e.g., weather, geopolitical issues).\n",
      "- **High Stakes**: Inefficiencies or errors can lead to significant cost overruns, delays, and lost revenue.\n",
      "- **Data-Driven but Fragmented**: There's a wealth of data across procurement, inventory, transportation, and distribution, but often it’s siloed or underutilized.\n",
      "\n",
      "### What Could an Agentic AI Do?\n",
      "- **Proactive Decision-Making**: Instead of simply responding to requests or queries, an Agentic AI could autonomously monitor supply chain conditions, identify risks or inefficiencies, and initiate corrective actions without waiting for human instructions.\n",
      "- **End-to-End Optimization**: It could negotiate with suppliers, optimize routes for delivery, dynamically adjust inventory levels, or reroute shipments in response to real-time conditions.\n",
      "- **Multi-Agent Coordination**: Deploy multiple specialized AI agents collaborating—one monitoring geopolitical risks, another analyzing customer demand trends, another optimizing warehouse operations.\n",
      "- **Learning and Improvement**: Continuously learn from outcomes to improve future decisions, build resilience, and adapt to new market conditions.\n",
      "\n",
      "### Impact Potential\n",
      "- **Cost Reduction**: Reduced inventory holding costs, more efficient transport logistics, fewer delays.\n",
      "- **Resilience**: Rapid autonomous responses to disruptions.\n",
      "- **Sustainability**: Optimize routes and inventory to reduce waste and carbon footprint.\n",
      "- **Competitive Advantage**: Agile, intelligent supply chains can provide superior customer experiences and responsiveness.\n",
      "\n",
      "---\n",
      "\n",
      "Agentic AI in supply chain management could evolve from tools that assist humans into autonomous digital managers that actively drive strategic and operational improvements.\n"
     ]
    }
   ],
   "source": [
    "# First create the messages:\n",
    "messages = [{\"role\": \"user\", \"content\": \"Pick a business area that might be ripe for an Agentic AI opportunity\"}]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Then read the business idea:\n",
    "\n",
    "business_idea = response.choices[0].message.content\n",
    "print(business_idea)\n",
    "\n",
    "# And repeat! In the next message, include the business idea within the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Proposed Pain Point: **Delayed and Inefficient Disruption Response in Supply Chain Operations**\n",
      "\n",
      "**Context:**  \n",
      "Supply chains today face frequent disruptions—ranging from sudden supplier failures, geopolitical events, extreme weather, to transportation bottlenecks. Currently, many companies rely on manual monitoring and human intervention when disruptions occur. This reactionary approach causes delays in identifying issues and implementing solutions, leading to costly downtime, misaligned inventory, and customer dissatisfaction.\n",
      "\n",
      "**Why This Pain Point?**  \n",
      "- **Speed and Scale:** Human teams often cannot monitor vast, complex networks in real-time nor quickly synthesize all relevant data streams (supplier status, transport conditions, market news).  \n",
      "- **Coordination Challenges:** Response requires orchestrating multiple functions—procurement, warehousing, logistics, and sales—often working in siloed systems, causing fragmentation and slow decisions.  \n",
      "- **Proactive vs Reactive:** Most existing systems alert users to problems but do not autonomously act or optimize responses, relying heavily on manual workflows.  \n",
      "- **Economic Impact:** Delay in disruption management easily escalates costs through expedited shipping fees, excess safety inventory, missed sales, and damaged client relationships.\n",
      "\n",
      "---\n",
      "\n",
      "### How Agentic AI Could Address This Pain Point\n",
      "\n",
      "- **Autonomous Monitoring & Early Detection:** Continuously gather and analyze multi-source data (supplier health, transport status, geopolitical news, weather forecasts) to identify potential disruptions before they fully materialize.  \n",
      "- **Proactive Mitigation Actions:** Automatically initiate contingency plans such as rerouting shipments, reallocating inventory, or engaging backup suppliers without waiting for manual instructions.  \n",
      "- **Cross-Functional Coordination:** Collaborate among specialized AI agents representing procurement, logistics, and sales to optimize decisions in real-time and maintain alignment.  \n",
      "- **Learning & Adaptation:** Use feedback from past incidents to improve detection accuracy, response speed, and contingency effectiveness, gradually reducing downtime and reactive firefighting.\n",
      "\n",
      "---\n",
      "\n",
      "### Summary  \n",
      "**Pain Point:** Lagging and inefficient disruption response in supply chains significantly impacts cost, customer satisfaction, and operational stability.  \n",
      "**Agentic AI Opportunity:** Deploy autonomous agents capable of real-time monitoring, risk anticipation, and cross-functional automated mitigation to transform supply chain resilience from reactive to proactive—driving cost savings, agility, and competitive advantage.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Please propose a pain point in the business area of \" + business_idea}]\n",
    "\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "pain_point = response.choices[0].message.content\n",
    "print(pain_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here’s a detailed solution proposal leveraging agentic AI to address the pain point of delayed and inefficient disruption response in supply chain operations:\n",
      "\n",
      "---\n",
      "\n",
      "## Proposed Solution: Autonomous, Multi-Agent AI Ecosystem for Real-Time Supply Chain Disruption Management\n",
      "\n",
      "### 1. **System Architecture Overview**\n",
      "\n",
      "- **Multi-Agent AI Framework:**  \n",
      "  Deploy a network of specialized autonomous agents, each dedicated to a supply chain domain:\n",
      "  - **Supplier Intelligence Agent:** Monitors supplier performance, financial health, geopolitical risks, and compliance using real-time external databases and news feeds.\n",
      "  - **Logistics & Transportation Agent:** Tracks shipment progress, transport capacity, carrier reliability, and weather disruptions through GPS, IoT sensors, and traffic/weather APIs.\n",
      "  - **Inventory & Warehouse Agent:** Oversees stock levels, turnover rates, warehouse capacity, and alternative storage options.\n",
      "  - **Market Demand & Sales Agent:** Forecasts short-term demand fluctuations based on sales data, promotions, and market trends.\n",
      "  - **Coordination Agent:** Acts as the central orchestrator, integrating insights from domain agents and managing end-to-end decision-making.\n",
      "\n",
      "- **Data Integration Layer:**  \n",
      "  Aggregate internal data (ERP, TMS, WMS) and external sources (news, social media, satellite/weather data, market trends) into a centralized real-time data lake to fuel AI agents.\n",
      "\n",
      "### 2. **Key Functional Capabilities**\n",
      "\n",
      "- **Continuous, Autonomous Monitoring:**  \n",
      "  Agents run 24/7 scans of diverse, multi-source data to detect early warning signs—e.g., supplier financial instability, port closures, or forecasted storms—long before disruptions impact operations.\n",
      "\n",
      "- **Real-Time Risk Scoring & Prioritization:**  \n",
      "  Using advanced risk models and machine learning, agents assign risk levels to different nodes in the supply chain and prioritize issues by severity and potential impact on revenue and service levels.\n",
      "\n",
      "- **Automated Contingency Execution:**  \n",
      "  Upon identifying a disruption, agents autonomously assess activation of pre-approved contingency plans such as:  \n",
      "  - Switching to alternate suppliers with available capacity.  \n",
      "  - Rerouting shipments via less impacted transport corridors.  \n",
      "  - Adjusting inventory allocations across warehouses to meet forecasted demand.  \n",
      "  - Initiating demand shaping actions in coordination with sales teams.\n",
      "\n",
      "- **Cross-Functional Coordination & Decision-Making:**  \n",
      "  The Coordination Agent consolidates inputs, negotiates trade-offs (cost vs speed vs risk), and coordinates synchronized multi-party actions without human lag.\n",
      "\n",
      "- **Explainability and Human-in-the-Loop Oversight:**  \n",
      "  For high-impact decisions, the system generates transparent rationales and notifies human managers with actionable summaries—allowing quick overrides, feedback, and continuous learning.\n",
      "\n",
      "- **Machine Learning Feedback Loop:**  \n",
      "  Post-incident data feeds back into the system to refine predictive models, optimize contingency algorithms, and evolve risk thresholds.\n",
      "\n",
      "### 3. **Implementation Roadmap**\n",
      "\n",
      "- **Phase 1: Pilot Detection and Monitoring**  \n",
      "  Start with automated data integration and develop risk detection models for a limited set of suppliers and logistics partners. Provide alerts and decision support to human teams.\n",
      "\n",
      "- **Phase 2: Autonomous Response & Coordination**  \n",
      "  Expand agent responsibilities to trigger contingency protocols with predefined guardrails. Integrate cross-functional systems and build the orchestration layer.\n",
      "\n",
      "- **Phase 3: Full Autonomous Ecosystem & Continuous Improvement**  \n",
      "  Deploy feedback-driven learning, expanded data sources, and more sophisticated multi-agent negotiations to achieve fully autonomous disruption management dynamic enough to handle novel scenarios.\n",
      "\n",
      "### 4. **Expected Benefits**\n",
      "\n",
      "- **Accelerated Reaction Times:** Real-time detection and autonomous action reduce disruption response from hours or days to minutes.  \n",
      "- **Reduced Operational Costs:** Minimized expedited shipping, stockouts, and excess safety inventory.  \n",
      "- **Increased Resilience and Agility:** Adaptive scenario planning enables handling complex multi-factor disruptions.  \n",
      "- **Enhanced Cross-Functional Alignment:** Automated coordination breaks down silos, improving overall decision quality.  \n",
      "- **Improved Customer Satisfaction:** Higher fulfillment rates and fewer delays maintain trust and brand reputation.\n",
      "\n",
      "---\n",
      "\n",
      "## Summary\n",
      "\n",
      "By harnessing an autonomous multi-agent AI system with real-time monitoring, risk scoring, and proactive execution of contingency plans—supported by a data-driven orchestration layer—companies can transform supply chain disruption response from cumbersome and reactive to agile, efficient, and predictive. This approach drives significant cost savings, operational continuity, and competitive advantage in today’s uncertain global environment.\n"
     ]
    }
   ],
   "source": [
    "messages =[{\"role\": \"user\", \"content\": \"Please propose a solution to the pain point of \" + pain_point}]\n",
    "\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "solution = response.choices[0].message.content\n",
    "print(solution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here’s a detailed solution proposal leveraging agentic AI to address the pain point of delayed and inefficient disruption response in supply chain operations:\n",
       "\n",
       "---\n",
       "\n",
       "## Proposed Solution: Autonomous, Multi-Agent AI Ecosystem for Real-Time Supply Chain Disruption Management\n",
       "\n",
       "### 1. **System Architecture Overview**\n",
       "\n",
       "- **Multi-Agent AI Framework:**  \n",
       "  Deploy a network of specialized autonomous agents, each dedicated to a supply chain domain:\n",
       "  - **Supplier Intelligence Agent:** Monitors supplier performance, financial health, geopolitical risks, and compliance using real-time external databases and news feeds.\n",
       "  - **Logistics & Transportation Agent:** Tracks shipment progress, transport capacity, carrier reliability, and weather disruptions through GPS, IoT sensors, and traffic/weather APIs.\n",
       "  - **Inventory & Warehouse Agent:** Oversees stock levels, turnover rates, warehouse capacity, and alternative storage options.\n",
       "  - **Market Demand & Sales Agent:** Forecasts short-term demand fluctuations based on sales data, promotions, and market trends.\n",
       "  - **Coordination Agent:** Acts as the central orchestrator, integrating insights from domain agents and managing end-to-end decision-making.\n",
       "\n",
       "- **Data Integration Layer:**  \n",
       "  Aggregate internal data (ERP, TMS, WMS) and external sources (news, social media, satellite/weather data, market trends) into a centralized real-time data lake to fuel AI agents.\n",
       "\n",
       "### 2. **Key Functional Capabilities**\n",
       "\n",
       "- **Continuous, Autonomous Monitoring:**  \n",
       "  Agents run 24/7 scans of diverse, multi-source data to detect early warning signs—e.g., supplier financial instability, port closures, or forecasted storms—long before disruptions impact operations.\n",
       "\n",
       "- **Real-Time Risk Scoring & Prioritization:**  \n",
       "  Using advanced risk models and machine learning, agents assign risk levels to different nodes in the supply chain and prioritize issues by severity and potential impact on revenue and service levels.\n",
       "\n",
       "- **Automated Contingency Execution:**  \n",
       "  Upon identifying a disruption, agents autonomously assess activation of pre-approved contingency plans such as:  \n",
       "  - Switching to alternate suppliers with available capacity.  \n",
       "  - Rerouting shipments via less impacted transport corridors.  \n",
       "  - Adjusting inventory allocations across warehouses to meet forecasted demand.  \n",
       "  - Initiating demand shaping actions in coordination with sales teams.\n",
       "\n",
       "- **Cross-Functional Coordination & Decision-Making:**  \n",
       "  The Coordination Agent consolidates inputs, negotiates trade-offs (cost vs speed vs risk), and coordinates synchronized multi-party actions without human lag.\n",
       "\n",
       "- **Explainability and Human-in-the-Loop Oversight:**  \n",
       "  For high-impact decisions, the system generates transparent rationales and notifies human managers with actionable summaries—allowing quick overrides, feedback, and continuous learning.\n",
       "\n",
       "- **Machine Learning Feedback Loop:**  \n",
       "  Post-incident data feeds back into the system to refine predictive models, optimize contingency algorithms, and evolve risk thresholds.\n",
       "\n",
       "### 3. **Implementation Roadmap**\n",
       "\n",
       "- **Phase 1: Pilot Detection and Monitoring**  \n",
       "  Start with automated data integration and develop risk detection models for a limited set of suppliers and logistics partners. Provide alerts and decision support to human teams.\n",
       "\n",
       "- **Phase 2: Autonomous Response & Coordination**  \n",
       "  Expand agent responsibilities to trigger contingency protocols with predefined guardrails. Integrate cross-functional systems and build the orchestration layer.\n",
       "\n",
       "- **Phase 3: Full Autonomous Ecosystem & Continuous Improvement**  \n",
       "  Deploy feedback-driven learning, expanded data sources, and more sophisticated multi-agent negotiations to achieve fully autonomous disruption management dynamic enough to handle novel scenarios.\n",
       "\n",
       "### 4. **Expected Benefits**\n",
       "\n",
       "- **Accelerated Reaction Times:** Real-time detection and autonomous action reduce disruption response from hours or days to minutes.  \n",
       "- **Reduced Operational Costs:** Minimized expedited shipping, stockouts, and excess safety inventory.  \n",
       "- **Increased Resilience and Agility:** Adaptive scenario planning enables handling complex multi-factor disruptions.  \n",
       "- **Enhanced Cross-Functional Alignment:** Automated coordination breaks down silos, improving overall decision quality.  \n",
       "- **Improved Customer Satisfaction:** Higher fulfillment rates and fewer delays maintain trust and brand reputation.\n",
       "\n",
       "---\n",
       "\n",
       "## Summary\n",
       "\n",
       "By harnessing an autonomous multi-agent AI system with real-time monitoring, risk scoring, and proactive execution of contingency plans—supported by a data-driven orchestration layer—companies can transform supply chain disruption response from cumbersome and reactive to agile, efficient, and predictive. This approach drives significant cost savings, operational continuity, and competitive advantage in today’s uncertain global environment."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(solution))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One promising area in triage of live production software systems for applying Agentic AI is **Automated Incident Diagnosis and Initial Remediation**.\n",
      "\n",
      "### Why this area?\n",
      "\n",
      "- **Complexity and Volume**: Live production environments generate vast amounts of alerts and logs, making it challenging for human engineers to quickly identify the root cause and appropriate response.\n",
      "- **Rapid Context Gathering**: Effective triage requires gathering extensive context—logs, metrics, recent deployments, config changes, and system states—integrating data from multiple tools.\n",
      "- **Decision Making Under Uncertainty**: An AI agent can manage uncertain diagnostics using probabilistic reasoning, prioritizing hypotheses, and iteratively ruling them out.\n",
      "- **Multi-step Actions**: The agent can perform multi-turn, agentic actions such as querying logs, correlating alerts, testing assumptions (e.g., running diagnostic commands or synthetic checks), then applying safe remediation steps (e.g., restarting a service, rolling back a deployment).\n",
      "- **Reducing MTTR (Mean Time to Resolution)**: Automating initial diagnosis and actions can dramatically shorten incident resolution time, especially during off-hours or when on-call engineers are overwhelmed.\n",
      "\n",
      "### How Agentic AI fits in:\n",
      "\n",
      "- **Autonomous Data Exploration**: The AI agent proactively explores monitoring dashboards, log indices, and incident records to hypothesize causes.\n",
      "- **Interactive Querying**: It asks clarifying questions or requests more data if needed, either by pulling more data sources autonomously or querying human operators.\n",
      "- **Safe Action Execution**: Before applying any remediation, the agent runs impact assessments or rollbacks in staging environments or executes canary tests.\n",
      "- **Learning and Feedback**: Continuously improves its diagnostic and remediation policies via reinforcement learning from incident outcomes and human feedback.\n",
      "\n",
      "### Example scenario:\n",
      "\n",
      "1. Incident alert triggers Agentic AI.\n",
      "2. Agent gathers logs around the timestamp, correlates metrics spikes, and reviews recent changes.\n",
      "3. It hypothesizes a memory leak causing a service crash.\n",
      "4. Confirms by triggering a targeted synthetic test.\n",
      "5. Agent restarts the affected service and temporarily increases resource limits.\n",
      "6. Monitors system for stabilization.\n",
      "7. Alerts human engineers with a detailed report summarizing cause and applied fix.\n",
      "\n",
      "---\n",
      "\n",
      "In summary, **Automated Incident Diagnosis and Initial Remediation using Agentic AI** leverages autonomy, multi-step reasoning, and safe environment interaction—making it a highly ripe area for applying agentic AI to live production system triage.\n"
     ]
    }
   ],
   "source": [
    "# 1. create the message\n",
    "messages = [{\"role\": \"user\", \"content\": \"Pick an area in triage of live production software system that would be ripe for Agentic AI opportunity\"}]\n",
    "\n",
    "# 2. Make the call\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# 3. read the response - idea\n",
    "business_idea = response.choices[0].message.content\n",
    "print(business_idea)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here’s a concrete **pain point** in the domain of **Automated Incident Diagnosis and Initial Remediation** for live production software systems where Agentic AI can provide significant value:\n",
      "\n",
      "---\n",
      "\n",
      "### Pain Point: **Overwhelming Alert Fatigue and Diagnostic Bottlenecks in Multi-Tool Environments**\n",
      "\n",
      "- **Description:**  \n",
      "Live production systems emit a high volume of alerts and signals from diverse monitoring, logging, and deployment tools (e.g., Prometheus, ELK, Datadog, CI/CD pipelines). Human engineers struggle to manually aggregate, correlate, and interpret this data rapidly and accurately. This leads to **alert fatigue**, where critical issues may be overlooked among false positives or non-actionable warnings.\n",
      "\n",
      "- **Why it's critical:**  \n",
      "When incidents occur, the lack of a unified view and context forces engineers to sift through fragmented data sources, often duplicating effort or making incorrect assumptions. This slows down incident diagnosis, increases Mean Time To Detect (MTTD), and inflates Mean Time To Resolution (MTTR), ultimately impacting service reliability, customer experience, and operational costs.\n",
      "\n",
      "- **How Agentic AI addresses it:**  \n",
      "  - **Autonomous data collection:** Agentic AI can automatically gather and unify telemetry from multiple heterogeneous sources, creating a synthesized context snapshot without manual queries.  \n",
      "  - **Prioritized hypothesis generation:** Instead of passing all alerts indiscriminately, the AI triages and prioritizes based on probabilistic reasoning and historical incident data, focusing engineers’ attention on the most actionable signals.  \n",
      "  - **Multi-step probing:** The AI can run targeted diagnostics or synthetic transactions to confirm or reject hypotheses autonomously, reducing ambiguity before escalation.  \n",
      "  - **Safe initial remediation:** By executing controlled remediation steps (e.g., restarts, resource reallocations), the agent tests fixes while minimizing disruption, further speeding recovery.\n",
      "\n",
      "---\n",
      "\n",
      "### Summary\n",
      "\n",
      "The **pain point of alert fatigue and fragmented, manual cross-tool diagnosis bottlenecks** is a prime candidate for agentic AI enhancements in automated incident triage. By enabling autonomous, context-rich, and multi-step reasoning combined with safe environment interactions, Agentic AI can effectively reduce cognitive overload on engineers, accelerate incident resolution, and increase overall system reliability.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Please propose a pain point in the business area of \" + business_idea}]\n",
    "\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "pain_point = response.choices[0].message.content\n",
    "print(pain_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here's a proposed solution framework leveraging Agentic AI to address the pain point of **Overwhelming Alert Fatigue and Diagnostic Bottlenecks in Multi-Tool Environments**:\n",
      "\n",
      "---\n",
      "\n",
      "## Proposed Solution: **Agentic AI-Based Unified Incident Diagnosis and Initial Remediation Platform**\n",
      "\n",
      "### 1. **Unified Data Ingestion and Contextualization Layer**\n",
      "\n",
      "- **Automated multi-source telemetry integration:**  \n",
      "  Develop connectors and adapters that continuously ingest alerts, logs, metrics, and events from all relevant tools (Prometheus, ELK, Datadog, CI/CD pipelines, cloud provider monitoring, etc.) into a centralized data lake or graph-based knowledge repository.\n",
      "\n",
      "- **Context synthesis engine:**  \n",
      "  Use AI techniques (knowledge graphs, embedding-based similarity, causal inference models) to correlate disparate signals, map them onto shared system topology, service dependencies, recent deployments, and historical incidents, producing a rich, unified snapshot of the incident context.\n",
      "\n",
      "### 2. **Probabilistic Alert Triage and Hypothesis Generation**\n",
      "\n",
      "- **Alert de-duplication and scoring:**  \n",
      "  Leverage Bayesian or machine learning models trained on historical incident data to cluster related alerts and suppress noise or false positives.\n",
      "\n",
      "- **Hypothesis engine:**  \n",
      "  Generate ranked incident root-cause hypotheses based on correlated symptoms, system context, and known failure modes (e.g., dependency failures, resource exhaustion).\n",
      "\n",
      "- **Explainability:**  \n",
      "  Present reasoning chains and confidence levels behind top hypotheses for human engineer review, reducing cognitive load and building trust.\n",
      "\n",
      "### 3. **Autonomous Multi-Step Diagnostic Probing**\n",
      "\n",
      "- **Targeted synthetic tests:**  \n",
      "  The agent executes safe, automated probes such as health checks, synthetic transactions, or targeted log queries to refine and validate/refute hypotheses.\n",
      "\n",
      "- **Adaptive diagnostic workflows:**  \n",
      "  Depending on probe results, trigger next-step diagnostics, narrowing down root cause iteratively.\n",
      "\n",
      "### 4. **Safe and Reversible Initial Remediation Orchestration**\n",
      "\n",
      "- **Controlled remediation policies:**  \n",
      "  Agentic AI executes low-risk remediation actions (e.g., service restarts, rolling back recent deploys, resource scaling) within pre-defined guardrails.\n",
      "\n",
      "- **Continuous monitoring and rollback:**  \n",
      "  Automatically monitor post-remediation system state; if regressions or failures are detected, promptly rollback actions.\n",
      "\n",
      "- **Human-in-the-loop escalation:**  \n",
      "  After initial remediation attempts, escalate the incident with synthesized findings, actions taken, and confidence levels to on-call engineers for further intervention if needed.\n",
      "\n",
      "### 5. **Feedback Loop for Continuous Learning**\n",
      "\n",
      "- **Incident postmortem integration:**  \n",
      "  Automatically ingest human postmortems and incident resolutions to refine models over time.\n",
      "\n",
      "- **Active learning and update:**  \n",
      "  Continuously improve alert triage, hypothesis generation, and remediation policies using real-world feedback.\n",
      "\n",
      "---\n",
      "\n",
      "## Expected Benefits\n",
      "\n",
      "- **Reduced alert noise and cognitive overload** by concentrating engineer attention on truly actionable signals.\n",
      "- **Faster root cause identification** due to integrated, multi-tool context and AI-powered reasoning.\n",
      "- **Accelerated incident resolution** through autonomous probing and safe initial remediation steps.\n",
      "- **Improved service reliability and operational efficiency** by minimizing human error, wasted effort, and downtime.\n",
      "- **Greater trust and adoption** by ensuring transparency, safe operation boundaries, and human oversight.\n",
      "\n",
      "---\n",
      "\n",
      "## Implementation Considerations\n",
      "\n",
      "- Build modular, extensible architecture to integrate with evolving tooling ecosystems.\n",
      "- Emphasize security and governance, especially around autonomous remediation capabilities.\n",
      "- Provide clear audit trails and human override mechanisms.\n",
      "- Start with pilot projects on non-critical systems gradually increasing scope and autonomy.\n",
      "\n",
      "---\n",
      "\n",
      "**In summary**, this approach—centered on an agentic AI capable of unified data fusion, probabilistic reasoning, autonomous diagnostics, and controlled remediation—effectively alleviates the pain of alert fatigue and diagnostic bottlenecks in complex production environments, transforming incident response into a more scalable, efficient, and reliable process.\n"
     ]
    }
   ],
   "source": [
    "messages =[{\"role\": \"user\", \"content\": \"Please propose a solution to the pain point of \" + pain_point}]\n",
    "\n",
    "response = openai_python_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "solution = response.choices[0].message.content\n",
    "print(solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Here's a proposed solution framework leveraging Agentic AI to address the pain point of **Overwhelming Alert Fatigue and Diagnostic Bottlenecks in Multi-Tool Environments**:\n",
       "\n",
       "---\n",
       "\n",
       "## Proposed Solution: **Agentic AI-Based Unified Incident Diagnosis and Initial Remediation Platform**\n",
       "\n",
       "### 1. **Unified Data Ingestion and Contextualization Layer**\n",
       "\n",
       "- **Automated multi-source telemetry integration:**  \n",
       "  Develop connectors and adapters that continuously ingest alerts, logs, metrics, and events from all relevant tools (Prometheus, ELK, Datadog, CI/CD pipelines, cloud provider monitoring, etc.) into a centralized data lake or graph-based knowledge repository.\n",
       "\n",
       "- **Context synthesis engine:**  \n",
       "  Use AI techniques (knowledge graphs, embedding-based similarity, causal inference models) to correlate disparate signals, map them onto shared system topology, service dependencies, recent deployments, and historical incidents, producing a rich, unified snapshot of the incident context.\n",
       "\n",
       "### 2. **Probabilistic Alert Triage and Hypothesis Generation**\n",
       "\n",
       "- **Alert de-duplication and scoring:**  \n",
       "  Leverage Bayesian or machine learning models trained on historical incident data to cluster related alerts and suppress noise or false positives.\n",
       "\n",
       "- **Hypothesis engine:**  \n",
       "  Generate ranked incident root-cause hypotheses based on correlated symptoms, system context, and known failure modes (e.g., dependency failures, resource exhaustion).\n",
       "\n",
       "- **Explainability:**  \n",
       "  Present reasoning chains and confidence levels behind top hypotheses for human engineer review, reducing cognitive load and building trust.\n",
       "\n",
       "### 3. **Autonomous Multi-Step Diagnostic Probing**\n",
       "\n",
       "- **Targeted synthetic tests:**  \n",
       "  The agent executes safe, automated probes such as health checks, synthetic transactions, or targeted log queries to refine and validate/refute hypotheses.\n",
       "\n",
       "- **Adaptive diagnostic workflows:**  \n",
       "  Depending on probe results, trigger next-step diagnostics, narrowing down root cause iteratively.\n",
       "\n",
       "### 4. **Safe and Reversible Initial Remediation Orchestration**\n",
       "\n",
       "- **Controlled remediation policies:**  \n",
       "  Agentic AI executes low-risk remediation actions (e.g., service restarts, rolling back recent deploys, resource scaling) within pre-defined guardrails.\n",
       "\n",
       "- **Continuous monitoring and rollback:**  \n",
       "  Automatically monitor post-remediation system state; if regressions or failures are detected, promptly rollback actions.\n",
       "\n",
       "- **Human-in-the-loop escalation:**  \n",
       "  After initial remediation attempts, escalate the incident with synthesized findings, actions taken, and confidence levels to on-call engineers for further intervention if needed.\n",
       "\n",
       "### 5. **Feedback Loop for Continuous Learning**\n",
       "\n",
       "- **Incident postmortem integration:**  \n",
       "  Automatically ingest human postmortems and incident resolutions to refine models over time.\n",
       "\n",
       "- **Active learning and update:**  \n",
       "  Continuously improve alert triage, hypothesis generation, and remediation policies using real-world feedback.\n",
       "\n",
       "---\n",
       "\n",
       "## Expected Benefits\n",
       "\n",
       "- **Reduced alert noise and cognitive overload** by concentrating engineer attention on truly actionable signals.\n",
       "- **Faster root cause identification** due to integrated, multi-tool context and AI-powered reasoning.\n",
       "- **Accelerated incident resolution** through autonomous probing and safe initial remediation steps.\n",
       "- **Improved service reliability and operational efficiency** by minimizing human error, wasted effort, and downtime.\n",
       "- **Greater trust and adoption** by ensuring transparency, safe operation boundaries, and human oversight.\n",
       "\n",
       "---\n",
       "\n",
       "## Implementation Considerations\n",
       "\n",
       "- Build modular, extensible architecture to integrate with evolving tooling ecosystems.\n",
       "- Emphasize security and governance, especially around autonomous remediation capabilities.\n",
       "- Provide clear audit trails and human override mechanisms.\n",
       "- Start with pilot projects on non-critical systems gradually increasing scope and autonomy.\n",
       "\n",
       "---\n",
       "\n",
       "**In summary**, this approach—centered on an agentic AI capable of unified data fusion, probabilistic reasoning, autonomous diagnostics, and controlled remediation—effectively alleviates the pain of alert fatigue and diagnostic bottlenecks in complex production environments, transforming incident response into a more scalable, efficient, and reliable process."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(solution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
